{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# # Data Splitting and Model Evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "815cffe6e134a079"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# # Data Splitting Methods\n",
    "# - Random Train-Test Split\n",
    "# - Stratified Train-Test Split\n",
    "# - Holdout Method\n",
    "# - Cross Validation\n",
    "# - Leave One Out Cross Validation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a880a672cac45add"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data/Iris.csv')\n",
    "print(df.describe(include='all'))\n",
    "\n",
    "# Display the Species class distribution\n",
    "target_count = df.Species.value_counts()\n",
    "print(target_count)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # Random Train-Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into 70% training and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, :-1], df.iloc[:, -1], test_size=0.3, random_state=42)\n",
    "\n",
    "# Display the shape of the training and test sets\n",
    "print('Random Train-Test Split, Training set shape:', X_train.shape, y_train.shape)\n",
    "print('Random Train-Test Split, Test set shape:', X_test.shape, y_test.shape)\n",
    "\n",
    "# Display the Species class distribution of the training and test sets\n",
    "print('Training set class distribution:')\n",
    "print(y_train.value_counts())\n",
    "print('Test set class distribution:')\n",
    "print(y_test.value_counts())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba4b07f4d81b8e85"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # Stratified Train-Test Split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Create stratified sampling object\n",
    "stratified_split = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split dataset into training and test sets using stratified sampling\n",
    "for train_index, test_index in stratified_split.split(df.iloc[:, :-1], df.iloc[:, -1]):\n",
    "    X_train_strat, X_test_strat = df.iloc[train_index, :-1], df.iloc[test_index, :-1]\n",
    "    y_train_strat, y_test_strat = df.iloc[train_index, -1], df.iloc[test_index, -1]\n",
    "\n",
    "# Display the shape of the training and test sets\n",
    "print('Stratified Train-Test Split, Training set shape:', X_train_strat.shape, y_train_strat.shape)\n",
    "print('Stratified Train-Test Split, Test set shape:', X_test_strat.shape, y_test_strat.shape)\n",
    "\n",
    "# Display the Species class distribution of the training and test sets\n",
    "print('Training set class distribution:')\n",
    "print(y_train_strat.value_counts())\n",
    "print('Test set class distribution:')\n",
    "print(y_test_strat.value_counts())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4dba8e9a0a8904d2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # # Holdout Validation with Validation Set\n",
    "# Split the dataset into 60% training, 20% validation, and 20% test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(df.iloc[:, :-1], df.iloc[:, -1], test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Display the shape of the training, validation, and test sets\n",
    "print('Holdout Validation with Validation Set, Training set shape:', X_train.shape, y_train.shape)\n",
    "print('Holdout Validation with Validation Set, Validation set shape:', X_val.shape, y_val.shape)\n",
    "print('Holdout Validation with Validation Set, Test set shape:', X_test.shape, y_test.shape)\n",
    "\n",
    "# Display the Species class distribution of the training, validation, and test sets\n",
    "print('Training set class distribution:')\n",
    "print(y_train.value_counts())\n",
    "print('Validation set class distribution:')\n",
    "print(y_val.value_counts())\n",
    "print('Test set class distribution:')\n",
    "print(y_test.value_counts())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58fa90bddf616f04"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # # K-Fold Cross-Validation\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Create K-Fold cross-validation object\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Split dataset into training and test sets using K-Fold cross-validation\n",
    "for train_index, test_index in k_fold.split(df.iloc[:, :-1], df.iloc[:, -1]):\n",
    "    X_train_kfold, X_test_kfold = df.iloc[train_index, :-1], df.iloc[test_index, :-1]\n",
    "    y_train_kfold, y_test_kfold = df.iloc[train_index, -1], df.iloc[test_index, -1]\n",
    "\n",
    "# Display the shape of the training and test sets\n",
    "print('K-Fold Cross-Validation, Training set shape:', X_train_kfold.shape, y_train_kfold.shape)\n",
    "print('K-Fold Cross-Validation, Test set shape:', X_test_kfold.shape, y_test_kfold.shape)\n",
    "\n",
    "# Display the Species class distribution of the training and test sets\n",
    "print('Training set class distribution:')\n",
    "print(y_train_kfold.value_counts())\n",
    "print('Test set class distribution:')\n",
    "print(y_test_kfold.value_counts())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f3bd364412b1b7b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # Stratified K-Fold Cross-Validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Create stratified K-Fold cross-validation object\n",
    "stratified_k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Split dataset into training and test sets using stratified K-Fold cross-validation\n",
    "for train_index, test_index in stratified_k_fold.split(df.iloc[:, :-1], df.iloc[:, -1]):\n",
    "    X_train_strat_kfold, X_test_strat_kfold = df.iloc[train_index, :-1], df.iloc[test_index, :-1]\n",
    "    y_train_strat_kfold, y_test_strat_kfold = df.iloc[train_index, -1], df.iloc[test_index, -1]\n",
    "\n",
    "# Display the shape of the training and test sets\n",
    "print('Stratified K-Fold Cross-Validation, Training set shape:', X_train_strat_kfold.shape, y_train_strat_kfold.shape)\n",
    "print('Stratified K-Fold Cross-Validation, Test set shape:', X_test_strat_kfold.shape, y_test_strat_kfold.shape)\n",
    "\n",
    "# Display the Species class distribution of the training and test sets\n",
    "print('Training set class distribution:')\n",
    "print(y_train_strat_kfold.value_counts())\n",
    "print('Test set class distribution:')\n",
    "print(y_test_strat_kfold.value_counts())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5919303c619607db"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # Leave-One-Out Cross-Validation\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "# Create Leave-One-Out cross-validation object\n",
    "leave_one_out = LeaveOneOut()\n",
    "\n",
    "i = 0\n",
    "# Split dataset into training and test sets using Leave-One-Out cross-validation\n",
    "for train_index, test_index in leave_one_out.split(df.iloc[:, :-1], df.iloc[:, -1]):\n",
    "    X_train_loo, X_test_loo = df.iloc[train_index, :-1], df.iloc[test_index, :-1]\n",
    "    y_train_loo, y_test_loo = df.iloc[train_index, -1], df.iloc[test_index, -1]\n",
    "\n",
    "    print(\"Loop: \", i)\n",
    "    # Display the shape of the training and test sets\n",
    "    print('Leave-One-Out Cross-Validation, Training set shape:', X_train_loo.shape, y_train_loo.shape)\n",
    "    print('Leave-One-Out Cross-Validation, Test set shape:', X_test_loo.shape, y_test_loo.shape)\n",
    "\n",
    "    # Display the Species class distribution of the training and test sets\n",
    "    print('Training set class distribution:')\n",
    "    print(y_train_loo.value_counts())\n",
    "    print('Test set class distribution:')\n",
    "    print(y_test_loo.value_counts(), '\\n')\n",
    "\n",
    "    i += 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61e28e47c44507d0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# # Model Evaluation Metrics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f7b5efec55f16107"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# # Regression Metrics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "666737b1d95915e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Import Regression models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Load the dataset\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data/Iris.csv')\n",
    "\n",
    "# Encoding the Species column\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['Species'] = label_encoder.fit_transform(df['Species'])\n",
    "\n",
    "# Split the dataset into 70% training and 30% test\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split the dataset into 70% training and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, :-1], df.iloc[:, -1], test_size=0.3, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = round(mean_squared_error(y_test, y_pred), 2)\n",
    "mae = round(mean_absolute_error(y_test, y_pred), 2)\n",
    "r2 = round(r2_score(y_test, y_pred), 2)\n",
    "print('Mean Squared Error: {0}, Mean Absolute Error: {1}, R2 Score: {2}'.format(mse, mae, r2), '\\n')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4842a0229ad1793"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # Classification Metrics\n",
    "# Import libraries\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Load the dataset\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data/Iris.csv')\n",
    "\n",
    "# Encoding the Species column\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['Species'] = label_encoder.fit_transform(df['Species'])\n",
    "\n",
    "# Split the dataset into 70% training and 30% test\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split the dataset into 70% training and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, :-1], df.iloc[:, -1], test_size=0.3, random_state=42)\n",
    "\n",
    "# Import classifiers, DT\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Calculate the classification report\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred), '\\n')\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "presicion = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print('Accuracy: {0}, Precision: {1}, Recall: {2}, F1 Score: {3}'.format(accuracy, presicion, recall, f1), '\\n')\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46f9d7abe618d0c9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
